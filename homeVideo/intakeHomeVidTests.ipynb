{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the recent captures directory\n",
    "# for every folder\n",
    "# read in the files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "def getRepoPath():\n",
    "    cwd = os.getcwd()\n",
    "    delimiter = \"\\\\\" if \"\\\\\" in cwd else \"/\"\n",
    "    repoPath = delimiter.join(cwd.split(delimiter)[:cwd.split(delimiter).index(\"dataImport\")]) + delimiter\n",
    "    return repoPath\n",
    "repoPath = getRepoPath()\n",
    "sys.path.append(repoPath + \"dataImport/\")\n",
    "import rwWorkingTSDf\n",
    "from rwWorkingTSDf import writeWorkingTSDf, readWorkingTSDF, fnString_to_dt, dt_to_fnString\n",
    "recentCapPath = repoPath + \"recentCaptures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitVidopencv(input_file_location, boundary_indexes, output_paths):\n",
    "    cap = cv2.VideoCapture(input_file_location)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
    "    \n",
    "    for i, (start_frame, end_frame) in enumerate(boundary_indexes):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        out = cv2.VideoWriter(output_paths[i], fourcc, fps, (width, height))\n",
    "\n",
    "        for frame_idx in range(start_frame, end_frame):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            out.write(frame)\n",
    "\n",
    "        out.release()\n",
    "        print(f\"Saved: {output_paths[i]}\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "def geBulkLocation(time, responsiblePartyName, instanceName, developingPartyName, deviceName, dataType, dataSource):\n",
    "    dataFolderName = \"_\".join([responsiblePartyName, instanceName, developingPartyName, deviceName, dataType, dataSource]) + \"/\"\n",
    "    dataFolderName += time.strftime(\"%Y\") + \"/\" + time.strftime(\"%m-%d\") + \"/\"\n",
    "    return repoPath + \"bulkData/\" + dataFolderName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldersToImport = sorted(os.listdir(recentCapPath))\n",
    "for f in foldersToImport:\n",
    "    camInfo = f.split(\"_\")[:-2]\n",
    "    folderPath = recentCapPath + f + \"/\"\n",
    "    # get a list of file name bases (withouth the file types)\n",
    "    fileNameBases = sorted(list(set([x.split(\".\")[0] for x in os.listdir(folderPath) if x != \"new.mp4\"])))\n",
    "    \n",
    "    # combine all parquets\n",
    "    for i, baseFileName in enumerate(fileNameBases):\n",
    "        source = folderPath + baseFileName + \".parquet.gzip\"\n",
    "        rDf = pd.read_parquet(source)\n",
    "        rDf.index = rDf.index.tz_convert('UTC')\n",
    "        if i == 0:\n",
    "            readDf = rDf\n",
    "        else:\n",
    "            readDf = pd.concat([readDf, rDf])\n",
    "\n",
    "\n",
    "    # for each file in a folder\n",
    "    for baseFileName in fileNameBases:\n",
    "        startTime = fnString_to_dt(baseFileName.split(\"_\")[-2]).astimezone(ZoneInfo(\"UTC\"))\n",
    "        endTime = fnString_to_dt(baseFileName.split(\"_\")[-1]).astimezone(ZoneInfo(\"UTC\"))\n",
    "        # if not a boundary file rename, move and contuinue\n",
    "        if startTime.day == endTime.day:\n",
    "            # generate new file name\n",
    "            newFileName = dt_to_fnString(startTime) + \"_\" + dt_to_fnString(endTime) + \".mp4\"\n",
    "            source = folderPath + baseFileName + \".mp4\"\n",
    "            destination = geBulkLocation(startTime, *camInfo)\n",
    "            # move to the right location\n",
    "            if not os.path.exists(destination):\n",
    "                print(\"made directory \" + destination)\n",
    "                os.makedirs(destination)\n",
    "            shutil.copy2(source, destination  + newFileName)\n",
    "            continue\n",
    "\n",
    "        # the file contains more than one day of data\n",
    "        frameTimes = readDf.copy()\n",
    "        # print(frameTimes.head().index)\n",
    "        frameTimes.index = pd.to_datetime(frameTimes.index, utc=True)\n",
    "        frameTimes['date'] = frameTimes.index.normalize()\n",
    "        boundaries = frameTimes.groupby('date').apply(lambda x: (x.index[0], x.index[-1]), include_groups=False)\n",
    "        index_boundaries = [(frameTimes.index.get_loc(start), frameTimes.index.get_loc(end))\n",
    "                                for day, (start, end) in boundaries.items()]\n",
    "        \n",
    "        output_paths = [geBulkLocation(x[0], *camInfo) + \n",
    "                        dt_to_fnString(x[0]) + \"_\" + dt_to_fnString(x[1]) + \".mp4\" \n",
    "                        for x in boundaries]\n",
    "\n",
    "        splitVidopencv(folderPath + baseFileName  + \".mp4\", index_boundaries, output_paths)\n",
    "        writeWorkingTSDf(*camInfo, readDf)\n",
    "\n",
    "    # delete the folder\n",
    "    #os.rmdir(recentCapPath + f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
